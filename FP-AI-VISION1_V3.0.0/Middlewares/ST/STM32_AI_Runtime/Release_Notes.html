<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Release Notes for STM32_AI_Runtime Middleware Component</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="../../../_htmresc/mini-st.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="row">
<div class="col-sm-12 col-lg-4">
<div class="card fluid">
<div class="sectione dark">
<center>
<h1 id="release-notes-for-stm32_ai_runtime-library"><small>Release Notes for</small> <strong>STM32_AI_Runtime Library</strong></h1>
<p>Copyright © 2020 STMicroelectronics</p>
<a href="https://www.st.com" class="logo"><img src="../../../_htmresc/st_logo.png" alt="ST logo" /></a>
</center>
</div>
</div>
<h1 id="license">License</h1>
<p>This software package is licensed by ST under ST license SLA0044, the “License”; You may not use this component except in compliance with the License. You may obtain a copy of the License at:</p>
<p><a href="http://www.st.com/SLA0044">http://www.st.com/SLA0044</a></p>
<h1 id="purpose">Purpose</h1>
<p>STM32_AI_Runtime is a neural network library optimized for STM32.</p>
<p>Here is the list of references to user documents:</p>
<ul>
<li><a href="https://www.st.com/content/ccc/resource/technical/document/user_manual/group1/69/bb/ec/5d/78/16/43/ce/DM00570145/files/DM00570145.pdf/jcr:content/translations/en.DM00570145.pdf">UM2526</a> : Getting started with X-CUBE-AI Expansion Package for Artificial Intelligence (AI)</li>
</ul>
</div>
<section id="update-history" class="col-sm-12 col-lg-8">
<h1>Update History</h1>
<div class="collapse">
<input type="checkbox" id="collapse-section5" checked aria-hidden="true"> <label for="collapse-section5" aria-hidden="true"><strong>V6.0.0 / 10-March-2021</strong></label>
<div>
<h2 id="main-changes">Main Changes</h2>
<ul>
<li>new operators/layers
<ul>
<li>KERAS: Average, Custom layer, Lambda wrapper: tf.math.abs, tf.math.acos, tf.gather.. 25+</li>
<li>ONNX: ConstantOfShape, DequantizeLinear, Equal, Gather, Greater, GreaterOrEqual, Identity, Less, LessOrEqual, Mean, Neg, Not, Or, QLinearConv, QLinearMatMul, QuantizeLinear, ReduceL1, ReduceL2, ReduceSumSquare, Shape, Xor</li>
<li>TFLITE: EQUAL, EXPAND_DIMS, FILL, GATHER, GREATER, GREATER_EQUAL, L2_NORMALIZATION, LESS, LESS_EQUAL, LOGICAL_AND, LOGICAL_NOT, LOGICAL_OR, MIRROR_PAD, PACK, REDUCE_ANY, REDUCE_MAX, REDUCE_MIN, REDUCE_PROD, SHAPE, SQUARE, TILE, UNIDIRECTIONAL_SEQUENCE_LSTM</li>
</ul></li>
<li>remove Qmn format support</li>
</ul>
<h1 id="major-bug-fixes">Major bug fixes</h1>
<ul>
<li>fix problems with shape of RepeatVector and recurrent layers</li>
<li>fix TFlite L2_Normalization import</li>
<li>fix bug on Conv2D float margin computation</li>
<li>fix problem when scale bias layer is merged in convolutional layer with zero bias</li>
<li>fix observer API to model with only one layer</li>
<li>enhance eltwise optimization</li>
<li>improve integer clip support</li>
<li>fix ResizeBilinear TFLite op (half_pixel_centers parameter support for +TF2 version)</li>
</ul>
<h2 id="contents">Contents</h2>
<ul>
<li>Neural Network library generated by <a href="https://www.st.com/en/embedded-software/x-cube-ai.html">X-CUBE-AI</a> V6.0.0</li>
</ul>
</div>
</div>
<div class="collapse">
<input type="checkbox" id="collapse-section4" aria-hidden="true"> <label for="collapse-section4" aria-hidden="true"><strong>V5.2.0 / 5-October-2020</strong></label>
<div>
<h2 id="main-changes-1">Main Changes</h2>
<ul>
<li>adding support for <strong>relocatable binary model</strong></li>
<li>TFLite and Keras importers are now fully based on <strong>TensorFlow 2.3</strong></li>
<li>remove the Keras.io support</li>
<li>up-to Keras version 2.4.0 model can be imported</li>
<li>add support to allocate the output buffers in activations buffer</li>
<li>performance improvement (with conv2D int8) wherever weights location (in internal or external flash)</li>
<li>bugs fixes / <strong>no new operator</strong></li>
</ul>
<p><strong>Note</strong> – The support of the following deprecated toolboxes is not maintained in future releases:</p>
<ul>
<li>Lasagne: [https://lasagne.readthedocs.io/en/latest/][LASAGNE]</li>
<li>Caffe: [https://caffe.berkeleyvision.org/][CAFFE]</li>
<li>ConvNetJs: [https://cs.stanford.edu/people/karpathy/convnetjs/][CONV_NET_JS]</li>
</ul>
<p><strong>Note</strong> – Qm,n arithmetic is a legacy support, it will be deprecated in future releases.</p>
<h2 id="contents-1">Contents</h2>
<ul>
<li>Neural Network library generated by <a href="https://www.st.com/en/embedded-software/x-cube-ai.html">X-CUBE-AI</a> V5.2.0</li>
</ul>
</div>
</div>
<div class="collapse">
<input type="checkbox" id="collapse-section3" aria-hidden="true"> <label for="collapse-section3" aria-hidden="true"><strong>V5.1.2 / 24-July-2020</strong></label>
<div>
<h2 id="main-changes-2">Main Changes</h2>
<ul>
<li>Enhancements of the User Interface
<ul>
<li>New graph to display the C-graph (operators and associated tensors)</li>
<li>New graph to display the usage of the “activations” buffer</li>
</ul></li>
<li>C-Code generation
<ul>
<li>Adding support to generate a c-array by weight/bias tensor</li>
<li>Adding textual c-graph description (operators and associated tensors) in the reports</li>
<li>Lighter network-runtime library support. Granularity of the inference kernel functions are aligned on the used integer scheme to decrease the code size.</li>
<li>Improvement of the memory peak usage (RAM and ROM size)</li>
</ul></li>
<li>Embedded inference client API extension
<ul>
<li>Adding platform observer API</li>
</ul></li>
<li>Validation
<ul>
<li>Adding support for int8/uint8 validation files</li>
</ul></li>
<li>System performance application
<ul>
<li>Adding executing time by layer</li>
</ul></li>
<li>Documentation
<ul>
<li>Adding specific article for the quantization a spects</li>
</ul></li>
</ul>
<p><strong>Note</strong> – User should be aware that <em>Qm,n</em> arithmetic is a legacy support, it will be deprecated in the future release.</p>
<h2 id="major-bug-fixes-and-improvement">Major bug fixes and improvement</h2>
<ul>
<li>adding ONNX Softmax, Hardmax, LogSoftmax, Resize operators</li>
<li>upgrading subset of operators up-to Opset to 10 support of ONNX 1.6</li>
<li>adding batch normalization and mul/add support for integer layers</li>
<li>adding Keras simple RNNs support</li>
<li>adding support for quantized concat operator</li>
<li>removing system heap usage for recurrent layers</li>
<li>fixing support for Keras GRU/LSTM/RNN layers when use_bias==False</li>
<li>fixing support for Keras GRU/LSTM layers with non-default nonlinear function</li>
<li>fixing ONNX shape interpretation (Concat and Slice) for 2D tensors</li>
<li>fixing duplicated inputs for elementwise operators</li>
<li>fixing support for TFLite/ONNX model with multiple IO</li>
<li>fixing MACC calculation for ONNX GEMM layers</li>
<li>improving parsing of TFLite reshape operator</li>
<li>fixing parsing of Keras RepeatVector operator</li>
</ul>
<h2 id="contents-2">Contents</h2>
<ul>
<li>Neural Network library generated by <a href="https://www.st.com/en/embedded-software/x-cube-ai.html">X-CUBE-AI</a> V5.1.2</li>
</ul>
</div>
</div>
<div class="collapse">
<input type="checkbox" id="collapse-section2" aria-hidden="true"> <label for="collapse-section2" aria-hidden="true"><strong>V5.0.0 / 23-December-2019</strong></label>
<div>
<h2 id="main-changes-3">Main Changes</h2>
<ul>
<li>Support of ONNX floating-point network
<ul>
<li>A subset of operators from Opset 7, 8 and 9 of ONNX 1.6 is supported</li>
</ul></li>
<li>Adding “per-channel” support for quantized model
<ul>
<li>Enhanced support for Post-quantized and training-aware TensorFlow lite models</li>
<li>Keras post-quantization process update</li>
</ul></li>
<li>Support of Mutiple IO network
<ul>
<li>Model for multiple IO are now fully supported</li>
</ul></li>
<li>Bug fixes and enhancement
<ul>
<li>Improvement of the RAM usage</li>
</ul></li>
</ul>
<h2 id="contents-3">Contents</h2>
<ul>
<li>Neural Network library generated by <a href="https://www.st.com/en/embedded-software/x-cube-ai.html">X-CUBE-AI</a> V5.0.0</li>
</ul>
</div>
</div>
<div class="collapse">
<input type="checkbox" id="collapse-section1" aria-hidden="true"> <label for="collapse-section1" aria-hidden="true"><strong>V4.0.0 / 19-July-2019</strong></label>
<div>
<h2 id="main-changes-4">Main Changes</h2>
<h3 id="first-official-release-of-stm32_ai-library"><strong>First official release of STM32_AI library</strong></h3>
<h2 id="contents-4">Contents</h2>
<ul>
<li>Neural Network library generated by <a href="https://www.st.com/en/embedded-software/x-cube-ai.html">X-CUBE-AI</a> V4.0.0</li>
</ul>
</div>
</div>
</div>
</section>
</div>
</div>
<footer class="sticky">
<p>For complete documentation on <strong>STM32 Microcontrollers </strong>, visit: <a href="http://www.st.com/STM32">www.st.com</a></p>
This release note uses up to date web standards and, for this reason, should not be opened with Internet Explorer but preferably with popular browsers such as Google Chrome, Mozilla Firefox, Opera or Microsoft Edge.
</footer>
</body>
</html>
